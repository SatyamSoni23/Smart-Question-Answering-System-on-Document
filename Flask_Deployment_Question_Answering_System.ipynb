{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flask Deployment Question Answering System.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmVR62jYuxm_",
        "outputId": "e1e1d754-c41b-4669-9b74-890663546bdf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNC8aayhvGWj"
      },
      "source": [
        "import os \n",
        "os.chdir('gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w0rNPITjMPl8",
        "outputId": "a593403e-60a8-4cd8-d509-f7b1e7b8091a"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R1yc1Q5MoEg"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_nlgmiiMuBz"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UehYX5tpvST9",
        "outputId": "c004506c-3a30-4cc5-ec10-64c7fc353061"
      },
      "source": [
        "!pip install pdfplumber\n",
        "!pip install nltk\n",
        "!pip install -U gensim\n",
        "!pip install flask-ngrok\n",
        "!pip install werkzeug\n",
        "!pip install numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfplumber\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/30/528bba4a8a2dde7b7e89475a1f1d7b3ed342073a76b4e7248cdd8393f058/pdfplumber-0.5.28.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20200517\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/c0/ef1c8758bbd86edb10b5443700aac97d0ba27a9ca2e7696db8cd1fdbd5a8/pdfminer.six-20200517-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 19.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (7.1.2)\n",
            "Collecting Wand\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/f6/05f043c099639b9017b7244791048a4d146dfea45b41a199aed373246d50/Wand-0.6.6-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (2.3.0)\n",
            "Collecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/16/9627ab0493894a11c68e46000dbcc82f578c8ff06bc2980dcd016aea9bd3/pycryptodome-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (3.0.4)\n",
            "Building wheels for collected packages: pdfplumber\n",
            "  Building wheel for pdfplumber (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfplumber: filename=pdfplumber-0.5.28-cp37-none-any.whl size=32222 sha256=64f2796bc3b18f385e3fcc40ef55c3da9edd70ef818cc07e40bfac58415b448b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9b/3d/37e37d93650be964fdd2a9babf174214fec8a0f4d222d474ab\n",
            "Successfully built pdfplumber\n",
            "Installing collected packages: pycryptodome, pdfminer.six, Wand, pdfplumber\n",
            "Successfully installed Wand-0.6.6 pdfminer.six-20200517 pdfplumber-0.5.28 pycryptodome-3.10.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/f1417772965652d4ca6f901515debcd9d6c5430969e8c02ee7737e6de61c/gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9MB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.1\n",
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Requirement already satisfied: werkzeug in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ4NZvm-vZ_D"
      },
      "source": [
        "def pdf_extract(file_name):\n",
        "  import pdfplumber\n",
        "  directory = \"docs\"\n",
        "  pdf_txt = \"\"\n",
        "  for file in os.listdir(directory):\n",
        "      filename = os.fsdecode(file)\n",
        "      if(filename == file_name):\n",
        "          pdf_txt = '' # new line\n",
        "          with pdfplumber.open(directory + '/' + filename) as pdf:\n",
        "              for pdf_page in pdf.pages:\n",
        "                single_page_text = pdf_page.extract_text()\n",
        "                pdf_txt = pdf_txt + '\\n' + single_page_text\n",
        "  return pdf_txt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrssKQfIv9aH",
        "outputId": "20ce629e-6f02-46eb-9ac0-917b7026c03f"
      },
      "source": [
        "import re\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "def clean_sentence(sentence, stopwords=False):\n",
        "  sentence = sentence.lower().strip()\n",
        "  sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "  if stopwords:\n",
        "    sentence = remove_stopwords(sentence)\n",
        "  return sentence\n",
        "\n",
        "def get_cleaned_sentences(tokens, stopwords=False):\n",
        "  cleaned_sentences = []\n",
        "  for row in tokens:\n",
        "    cleaned = clean_sentence(row, stopwords)\n",
        "    cleaned_sentences.append(cleaned)\n",
        "  return cleaned_sentences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PifH7rLhqPYl"
      },
      "source": [
        "def retrieveAndPrintFAQAnswer(question_embedding, sentence_embeddings, sentences):\n",
        "  import sklearn\n",
        "  from sklearn.metrics.pairwise import cosine_similarity\n",
        "  max_sim = -1\n",
        "  index_sim = -1\n",
        "  for index, embedding in enumerate(sentence_embeddings):\n",
        "    sim = cosine_similarity(embedding, question_embedding)[0][0]\n",
        "    if sim > max_sim:\n",
        "      max_sim = sim\n",
        "      index_sim = index\n",
        "  \n",
        "  return index_sim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9fGZ9nyoPOT"
      },
      "source": [
        "def naive_drive(file_name, question):\n",
        "  pdf_txt = pdf_extract(file_name)\n",
        "  import nltk\n",
        "  import numpy\n",
        "  import pprint\n",
        "  nltk.download('punkt')\n",
        "  tokens = nltk.sent_tokenize(pdf_txt)\n",
        "  cleaned_sentences = get_cleaned_sentences(tokens, stopwords=True)\n",
        "  cleaned_sentences_with_stopwords = get_cleaned_sentences(tokens, stopwords=False)\n",
        "  sentences = cleaned_sentences_with_stopwords\n",
        "  sentence_words = [[word for word in document.split()]\n",
        "                    for document in sentences]\n",
        "\n",
        "  from gensim import corpora\n",
        "  dictionary = corpora.Dictionary(sentence_words)\n",
        "  bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]\n",
        "\n",
        "  question = clean_sentence(question, stopwords=False)\n",
        "  question_embedding = dictionary.doc2bow(question.split())\n",
        "\n",
        "  index = retrieveAndPrintFAQAnswer(question_embedding, bow_corpus, sentences)\n",
        "  return sentences[index]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsU3fwPyqigD",
        "outputId": "ea9f2544-c7f1-4124-cbd1-62d04d9c3d12"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "answer = naive_drive('fdi.pdf', question)\n",
        "print(answer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "make in india initiative has made significant achievements and presently focuses on 27 sectors \n",
            "under make in india 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsofBK6CsLna"
      },
      "source": [
        "==================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP6V6As0tN9y",
        "outputId": "b3062b7e-3cef-4254-fc53-e42bc8a05f35"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "v2w_model = None\n",
        "try:\n",
        "  v2w_model = gensim.models.Keyedvectors.load('./w2vecmodel.mod')\n",
        "  print(\"w2v Model Successfully loaded\")\n",
        "except:\n",
        "  v2w_model = api.load('word2vec-google-news-300')\n",
        "  v2w_model.save(\"./w2vecmodel.mod\")\n",
        "  print(\"w2v Model Saved\")\n",
        "\n",
        "w2vec_embedding_size = len(v2w_model['pc']) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "w2v Model Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4g7dL8ptVSY"
      },
      "source": [
        "def getWordVec(word, model):\n",
        "  import numpy\n",
        "  samp = model['pc']\n",
        "  vec = [0]*len(samp)\n",
        "  try:\n",
        "    vec = model[word]\n",
        "  except:\n",
        "    vec = [0]*len(samp)\n",
        "  return (vec)\n",
        "\n",
        "\n",
        "def getPhraseEmbedding(phrase, embeddingmodel):\n",
        "  import numpy\n",
        "  samp = getWordVec('computer', embeddingmodel)\n",
        "  vec = numpy.array([0]*len(samp))\n",
        "  den = 0;\n",
        "  for word in phrase.split():\n",
        "    den = den+1\n",
        "    vec = vec+numpy.array(getWordVec(word, embeddingmodel))\n",
        "  return vec.reshape(1, -1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvsIK44GsQCc"
      },
      "source": [
        "def word2vec_drive(file_name, question):\n",
        "  pdf_txt = pdf_extract(file_name)\n",
        "\n",
        "  import nltk\n",
        "  import numpy\n",
        "  import pprint\n",
        "  \n",
        "  nltk.download('punkt')\n",
        "  tokens = nltk.sent_tokenize(pdf_txt)\n",
        "  cleaned_sentences = get_cleaned_sentences(tokens, stopwords=True)\n",
        "  cleaned_sentences_with_stopwords = get_cleaned_sentences(tokens, stopwords=False)\n",
        "  sentences = cleaned_sentences_with_stopwords\n",
        "  sentence_words = [[word for word in document.split()]\n",
        "                    for document in sentences]\n",
        "\n",
        "  sent_embeddings = []\n",
        "  for sent in sentences:\n",
        "    sent_embeddings.append(getPhraseEmbedding(sent, v2w_model))\n",
        "\n",
        "  question_embedding = getPhraseEmbedding(question, v2w_model)\n",
        "  index = retrieveAndPrintFAQAnswer(question_embedding, sent_embeddings, cleaned_sentences_with_stopwords)\n",
        "  return cleaned_sentences_with_stopwords[index]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls8l92_wzyBX",
        "outputId": "9a599627-2b88-45bd-9d7f-0de694c5e20f"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "answer = word2vec_drive('fdi.pdf', question)\n",
        "print(answer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "recently government has taken various steps in addition to ongoing schemes to boost domestic \n",
            "and foreign investments in india\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRlTUtiCiy2"
      },
      "source": [
        "==================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw_gSSRADM1X",
        "outputId": "84022c6c-dc32-4386-b5cb-c4e0f5eacbf8"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_model = None\n",
        "try:\n",
        "  glove_model = gensim.models.Keyedvectors.load('./glovemodel.mod')\n",
        "  print(\"Glove Model Successfully loaded\")\n",
        "except:\n",
        "  glove_model = api.load('glove-twitter-25')\n",
        "  glove_model.save(\"./glovemodel.mod\")\n",
        "  print(\"Glove Model Saved\")\n",
        "\n",
        "glove_embedding_size = len(glove_model['pc'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "Glove Model Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ez4DND7Ch8w"
      },
      "source": [
        "def glove_drive(file_name, question):\n",
        "  pdf_txt = pdf_extract(file_name)\n",
        "\n",
        "  import nltk\n",
        "  import numpy\n",
        "  import pprint\n",
        "\n",
        "  nltk.download('punkt')\n",
        "  tokens = nltk.sent_tokenize(pdf_txt)\n",
        "  cleaned_sentences = get_cleaned_sentences(tokens, stopwords=True)\n",
        "  cleaned_sentences_with_stopwords = get_cleaned_sentences(tokens, stopwords=False)\n",
        "  sentences = cleaned_sentences_with_stopwords\n",
        "  sentence_words = [[word for word in document.split()]\n",
        "                    for document in sentences]\n",
        "\n",
        "  sent_embeddings = []\n",
        "  for sent in cleaned_sentences:\n",
        "    sent_embeddings.append(getPhraseEmbedding(sent, glove_model))\n",
        "\n",
        "  question_embedding = getPhraseEmbedding(question, glove_model)\n",
        "  index = retrieveAndPrintFAQAnswer(question_embedding, sent_embeddings, cleaned_sentences_with_stopwords)\n",
        "  return cleaned_sentences_with_stopwords[index]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH5tjHCXDzr4",
        "outputId": "a0555cf6-4bc5-463c-b79c-69eda378f6f5"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "answer = glove_drive('fdi.pdf', question)\n",
        "print(answer)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "as a result of the measures taken to improve the countrys investment climate india \n",
            "jumped to 63rd place in world banks ease of doing business ranking as per world banks doing \n",
            "business report dbr 2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ostyehoP89"
      },
      "source": [
        "==================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0amhOInhxQdE",
        "outputId": "568e6f25-0d81-4462-8ff6-b8fe11aca9b7"
      },
      "source": [
        "!pip install transformers==3.1.0\n",
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.1.0 in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.1.95)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (4.32.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0) (0.13.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCFSA4HDwH8m"
      },
      "source": [
        "def answer_question_bert(question, answer_text):\n",
        "\n",
        "    input_ids = tokenizer.encode(question, answer_text, max_length=512, truncation=True)\n",
        "\n",
        "    print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
        "\n",
        "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "    num_seg_a = sep_index + 1\n",
        "\n",
        "    num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "    assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
        "\n",
        "    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "    #print(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
        "    #print(f'score: {torch.max(start_scores)}')\n",
        "    score = float(torch.max(start_scores))\n",
        "    answer_start = torch.argmax(start_scores)\n",
        "    answer_end = torch.argmax(end_scores)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    answer = tokens[answer_start]\n",
        "\n",
        "    for i in range(answer_start + 1, answer_end + 1):\n",
        "\n",
        "        if tokens[i][0:2] == ' ':\n",
        "            answer += tokens[i][2:]\n",
        "\n",
        "        else:\n",
        "            answer += ' ' + tokens[i]\n",
        "    return answer, score\n",
        "    #print('Answer: \"' + answer + '\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh5gaBvnxu6R"
      },
      "source": [
        "def expand_split_sentences(pdf_txt):\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  new_chunks = nltk.sent_tokenize(pdf_txt)\n",
        "  length = len(new_chunks)\n",
        "  #for i in range(length):\n",
        "    #tmp_token = tokenizer.encode(new_chunks[i])\n",
        "    #print('The input has a total of {:} tokens.'.format(len(tmp_token)))\n",
        "\n",
        "  new_df = [];\n",
        "  for i in range(length):\n",
        "    paragraph = \"\"\n",
        "    for j in range(i, length):\n",
        "      #tmp_str = paragraph + new_chunks[j]\n",
        "      tmp_token = tokenizer.encode(paragraph + new_chunks[j])\n",
        "      length_token = len(tmp_token)\n",
        "      if length_token < 510:\n",
        "        #print(length_token)\n",
        "        paragraph = paragraph + new_chunks[j]\n",
        "      else:\n",
        "        #print(length_token)\n",
        "        break;\n",
        "    #print(len(tokenizer.encode(paragraph)))\n",
        "    new_df.append(paragraph)\n",
        "  return new_df\n",
        "  #for i in new_df:\n",
        "    #print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtudlENRyB7j"
      },
      "source": [
        "def bert_drive(file_name, question):\n",
        "  text = pdf_extract(file_name)\n",
        "  max_score = 0;\n",
        "  final_answer = \"\"\n",
        "  new_df = expand_split_sentences(text)\n",
        "  for new_context in new_df:\n",
        "    #new_paragrapgh = new_paragrapgh + answer_question(question, answer_text)\n",
        "    ans, score = answer_question_bert(question, new_context)\n",
        "    if score > max_score:\n",
        "      max_score = score\n",
        "      final_answer = ans\n",
        "  return final_answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q95CQLNiyYsB",
        "outputId": "5bf3d7b3-42a0-444e-a335-3b3346058e83"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "print(bert_drive('fdi.pdf', question))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Query has 511 tokens.\n",
            "\n",
            "Query has 502 tokens.\n",
            "\n",
            "Query has 484 tokens.\n",
            "\n",
            "Query has 461 tokens.\n",
            "\n",
            "Query has 512 tokens.\n",
            "\n",
            "Query has 512 tokens.\n",
            "\n",
            "Query has 512 tokens.\n",
            "\n",
            "Query has 509 tokens.\n",
            "\n",
            "Query has 471 tokens.\n",
            "\n",
            "Query has 444 tokens.\n",
            "\n",
            "Query has 400 tokens.\n",
            "\n",
            "Query has 349 tokens.\n",
            "\n",
            "Query has 330 tokens.\n",
            "\n",
            "Query has 283 tokens.\n",
            "\n",
            "Query has 256 tokens.\n",
            "\n",
            "Query has 235 tokens.\n",
            "\n",
            "Query has 205 tokens.\n",
            "\n",
            "Query has 173 tokens.\n",
            "\n",
            "Query has 80 tokens.\n",
            "\n",
            "Query has 57 tokens.\n",
            "\n",
            "Query has 36 tokens.\n",
            "\n",
            "national infrastructure pipeline , reduction in corporate tax , easing liquid ##ity problems of n ##bf ##cs and banks , policy measures to boost domestic manufacturing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zimr1-jKLcC4"
      },
      "source": [
        "==================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "Sp3XzKBPjgro",
        "outputId": "6121ad89-936a-464f-f74c-30fca113a9ea"
      },
      "source": [
        "!pip install cdqa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cdqa in /usr/local/lib/python3.7/dist-packages (1.3.9)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from cdqa) (0.21.2)\n",
            "Requirement already satisfied: Flask==1.1.1 in /usr/local/lib/python3.7/dist-packages (from cdqa) (1.1.1)\n",
            "Requirement already satisfied: flask-cors==3.0.8 in /usr/local/lib/python3.7/dist-packages (from cdqa) (3.0.8)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.7/dist-packages (from cdqa) (1.2.0)\n",
            "Requirement already satisfied: tqdm==4.32.2 in /usr/local/lib/python3.7/dist-packages (from cdqa) (4.32.2)\n",
            "Requirement already satisfied: transformers==2.1.1 in /usr/local/lib/python3.7/dist-packages (from cdqa) (2.1.1)\n",
            "Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.7/dist-packages (from cdqa) (0.13.2)\n",
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.7/dist-packages (from cdqa) (3.2)\n",
            "Collecting pandas==0.25.0\n",
            "  Using cached https://files.pythonhosted.org/packages/3b/42/dc1f4820b95fbdbc9352ec9ad0f0c40db2122e1f2440ea53c7f9fbccf2b8/pandas-0.25.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: tika==1.19 in /usr/local/lib/python3.7/dist-packages (from cdqa) (1.19)\n",
            "Requirement already satisfied: prettytable==0.7.2 in /usr/local/lib/python3.7/dist-packages (from cdqa) (0.7.2)\n",
            "Requirement already satisfied: markdown==3.1.1 in /usr/local/lib/python3.7/dist-packages (from cdqa) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->cdqa) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->cdqa) (1.4.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->cdqa) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->cdqa) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->cdqa) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask==1.1.1->cdqa) (1.0.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors==3.0.8->cdqa) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1->cdqa) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1->cdqa) (0.0.45)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1->cdqa) (1.17.69)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1->cdqa) (0.1.95)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1->cdqa) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->cdqa) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->cdqa) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika==1.19->cdqa) (56.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask==1.1.1->cdqa) (1.1.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.1.1->cdqa) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.1.1->cdqa) (0.4.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.69 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.1.1->cdqa) (1.20.69)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.1.1->cdqa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.1.1->cdqa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.1.1->cdqa) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.1.1->cdqa) (1.24.3)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.32.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.1.0\n",
            "    Uninstalling pandas-1.1.0:\n",
            "      Successfully uninstalled pandas-1.1.0\n",
            "Successfully installed pandas-0.25.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Irg-m3taypMM",
        "outputId": "791de6e7-f51b-43a2-ad7d-993f2d6d479d"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "\n",
        "from cdqa.utils.converters import pdf_converter\n",
        "from cdqa.pipeline import QAPipeline\n",
        "from cdqa.utils.download import download_model\n",
        "download_model(model='bert-squad_1.1', dir='./models')\n",
        "!pip install pandas==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/autonotebook/__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading trained model...\n",
            "bert_qa.joblib already downloaded\n",
            "Collecting pandas==1.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/94/b1/f77f49cc7cc538b247f30c2ae7e3a50f29e44f0b1af32ff4869d7de3c762/pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.0) (1.15.0)\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.32.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cdqa 1.3.9 has requirement pandas==0.25.0, but you'll have pandas 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.25.0\n",
            "    Uninstalling pandas-0.25.0:\n",
            "      Successfully uninstalled pandas-0.25.0\n",
            "Successfully installed pandas-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvN9Zu_tMAaD"
      },
      "source": [
        "def fine_tuning_drive(question):\n",
        "  df = pdf_converter(directory_path=\"docs/\")\n",
        "  pd.set_option('display.max_colwidth', -1)\n",
        "  df.head()\n",
        "  cdqa_pipeline = QAPipeline(reader='./models/bert_qa.joblib', max_df=1.0)\n",
        "  cdqa_pipeline.fit_retriever(df=df)\n",
        "  import joblib\n",
        "  joblib.dump(cdqa_pipeline, './models/bert_qa_custom.joblib')\n",
        "  cdqa_pipeline=joblib.load('./models/bert_qa_custom.joblib')\n",
        "  prediction = cdqa_pipeline.predict(question, 1)\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EBBX58aNDDX",
        "outputId": "853ea857-98c1-46cc-822b-fc8de54ffb15"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "print(fine_tuning_drive(question))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('the National Infrastructure Pipeline, Reduction in Corporate Tax, easing liquidity problems of NBFCs and Banks', 'fdi', 'Recently, Government has taken various steps in addition to ongoing schemes to boost domestic and foreign investments in India. These include the National Infrastructure Pipeline, Reduction in Corporate Tax, easing liquidity problems of NBFCs and Banks, policy measures to boost domestic manufacturing. Government of India has also promoted domestic manufacturing of goods through public procurement orders, Phased Manufacturing Programme (PMP), Schemes for Production Linked Incentives of various Ministries. ', 8.688585496665787)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhmKrFyQn3R9"
      },
      "source": [
        "==================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgr1bnoJkYux"
      },
      "source": [
        "question = \"What were the various steps taken by the government to boost domestic and foreign investment in India ?\"\n",
        "answer = naive_drive('fdi.pdf', question)\n",
        "print(answer)\n",
        "answer = word2vec_drive('fdi.pdf', question)\n",
        "print(answer)\n",
        "answer = glove_drive('fdi.pdf', question)\n",
        "print(answer)\n",
        "answer = (bert_drive('fdi.pdf', question)\n",
        "print(answer)\n",
        "answer = fine_tuning_drive(question)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJULxNiVJJBV"
      },
      "source": [
        "from flask import *\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from werkzeug.utils import secure_filename\n",
        "from werkzeug.datastructures import  FileStorage\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def index():\n",
        "  if request.method == 'POST':\n",
        "    if(request.form.get('btn') == 'index'):\n",
        "      upload = request.files['upload']\n",
        "      path = \"docs\"\n",
        "      global file_name\n",
        "      file_name = upload.filename\n",
        "      print(file_name)\n",
        "      upload.save(os.path.join(path, secure_filename(upload.filename)))\n",
        "      return redirect(url_for('qa'))\n",
        "    elif (request.form.get('btn') == 'qa'):\n",
        "      question = request.form.get('question')\n",
        "      answer = \"\"\n",
        "      if(func == 'naive'):\n",
        "        answer = naive_drive(file_name, question)\n",
        "      elif(func == 'w2v'):\n",
        "        answer = word2vec_drive(file_name, question)\n",
        "      elif(func == 'glove'):\n",
        "        answer = glove_drive(file_name, question)\n",
        "      elif(func == 'bert'):\n",
        "        answer = bert_drive(file_name, question)\n",
        "      else:\n",
        "        answer = fine_tuning_drive(question)\n",
        "      #answer = fine_tuning_drive(question)\n",
        "      print(answer)\n",
        "      return render_template('qa.html', answer = answer, question = question)\n",
        "  return render_template('index.html')\n",
        "@app.route('/upload/', methods=['GET', 'POST'])\n",
        "def upload():\n",
        "    global func\n",
        "    func = request.args.get('type')\n",
        "    return render_template('upload.html')\n",
        "\n",
        "@app.route('/qa/', methods=['GET', 'POST'])\n",
        "def qa():\n",
        "    return render_template('qa.html')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufZqDNOzLD4I",
        "outputId": "dbc22d94-3c03-4e72-c0e2-1dd69e17eb01"
      },
      "source": [
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://ab6b6fb437db.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/May/2021 14:14:53] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/May/2021 14:14:55] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [09/May/2021 14:15:06] \"\u001b[37mGET /upload/?type=naive HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/May/2021 14:15:14] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fdi.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/May/2021 14:15:15] \"\u001b[37mGET /qa/ HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/May/2021 14:15:26] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "make in india initiative has made significant achievements and presently focuses on 27 sectors \n",
            "under make in india 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXNP8FLeUyA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}